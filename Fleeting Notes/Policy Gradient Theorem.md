202311011316
Status: #idea
Tags: [[Bandit, One Step MDP]]

# Policy Gradient Theorem

For any differentiable policy, 

Policy Gradient = Expectation of score function* Q value 

Move in a direction where we get better scores 

---
# References

1. https://www.youtube.com/watch?v=KHZVXao4qXs