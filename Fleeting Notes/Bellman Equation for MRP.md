202310241125
Status: #idea
Tags: [[Markov Reward Process]]

# Bellman Expectation Equation for MRP

1. ties current Reward with future Return in Markov Reward Process

![[Pasted image 20231024154929.png]]

2. take an action to get a good reward to end up in another state, but is the next state worth going? So based on immediate reward and future returns, what is the value of the "original" state?
3. Can be solved by inverting the matrix, Dynamic Programming, Monte-Carlo Evaluation, Temporal-Difference Learning

---
# References

1. https://www.youtube.com/watch?v=lfHX2hHRMVQ