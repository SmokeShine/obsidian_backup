202311291150
Status: #idea
Tags: [[Seq2Seq]]

# Context Vector

RNN final hidden state of encoder.

We can hidden state from intermediate time steps to create the context vector. Here we are assuming all hidden states have equal meaning.

Decoder uses output of last decoded step to create next value.


---
# References

1. https://towardsdatascience.com/knocking-on-transformers-door-attention-mechanism-explained-intuitively-df5d4fcecdf8