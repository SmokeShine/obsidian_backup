202310301609
Status: #idea
Tags: [[Experience Replay]]

# Deep Q-Network(DQN)

1. [[Q-Learning, SARSAMAX]] + [[Experience replay]]
2. Instead of value function of oracle, use a fixed q-targets
3. Even though SARSA issues with neural network, DQN works because:
	1. Two networks are used with one frozen
		1. CNN for Atari
	2. Experience replay breaks correlation
4. 
---
# References

1. https://www.youtube.com/watch?v=UoPei5o4fps