202411191151
Status: #idea
Tags:

# Gradient Accumulation

- Instead of doing gradient every mini batch, sum them up for a few batches and then do gradient calculation
- so, it is a batch of mini batches and we average by sum of length of mini batches
---
# References

1. 
