{
  "isChatComfy": true,
  "isUsingRag": true,
  "assistantLanguage": "en",
  "initialAssistantMessageContent": "Hello, I am your assistant. How can I help you?",
  "isIncognitoMode": true,
  "ollamaGenModel": {
    "model": "llama3.2",
    "baseUrl": "http://localhost:11434",
    "temperature": 0.3,
    "contextWindow": 2048,
    "lcModel": {
      "lc": 1,
      "type": "constructor",
      "id": [
        "langchain",
        "chat_models",
        "ollama",
        "ChatOllama"
      ],
      "kwargs": {
        "model": "phi3:mini",
        "base_url": "http://localhost:11434",
        "temperature": 0.3,
        "context_window": 1748,
        "lc_model": {
          "lc": 1,
          "type": "constructor",
          "id": [
            "langchain",
            "chat_models",
            "ollama",
            "ChatOllama"
          ],
          "kwargs": {
            "model": "phi3:mini",
            "base_url": "http://localhost:11434",
            "temperature": 0.3,
            "context_window": 1848,
            "lc_model": {
              "lc": 1,
              "type": "constructor",
              "id": [
                "langchain",
                "chat_models",
                "ollama",
                "ChatOllama"
              ],
              "kwargs": {
                "model": "phi3:mini",
                "base_url": "http://localhost:11434",
                "temperature": 0,
                "context_window": 1948,
                "lc_model": {
                  "lc": 1,
                  "type": "constructor",
                  "id": [
                    "langchain",
                    "chat_models",
                    "ollama",
                    "ChatOllama"
                  ],
                  "kwargs": {
                    "model": "phi3:medium",
                    "base_url": "http://localhost:11434",
                    "temperature": 0,
                    "context_window": 1648,
                    "lc_model": {
                      "lc": 1,
                      "type": "constructor",
                      "id": [
                        "langchain",
                        "chat_models",
                        "ollama",
                        "ChatOllama"
                      ],
                      "kwargs": {
                        "model": "phi3:medium",
                        "base_url": "http://localhost:11434",
                        "temperature": 0,
                        "context_window": 1748,
                        "lc_model": {
                          "lc": 1,
                          "type": "constructor",
                          "id": [
                            "langchain",
                            "chat_models",
                            "ollama",
                            "ChatOllama"
                          ],
                          "kwargs": {
                            "model": "phi3:medium",
                            "base_url": "http://localhost:11434",
                            "temperature": 0.36,
                            "context_window": 1848,
                            "lc_model": {
                              "lc": 1,
                              "type": "constructor",
                              "id": [
                                "langchain",
                                "chat_models",
                                "ollama",
                                "ChatOllama"
                              ],
                              "kwargs": {
                                "model": "phi3:medium",
                                "base_url": "http://localhost:11434",
                                "temperature": 0.27,
                                "context_window": 1948,
                                "lc_model": {
                                  "lc": 1,
                                  "type": "constructor",
                                  "id": [
                                    "langchain",
                                    "chat_models",
                                    "ollama",
                                    "ChatOllama"
                                  ],
                                  "kwargs": {
                                    "model": "llama3",
                                    "base_url": "http://localhost:11434",
                                    "temperature": 0.27,
                                    "context_window": 1648,
                                    "lc_model": {
                                      "lc": 1,
                                      "type": "constructor",
                                      "id": [
                                        "langchain",
                                        "chat_models",
                                        "ollama",
                                        "ChatOllama"
                                      ],
                                      "kwargs": {
                                        "model": "llama3",
                                        "base_url": "http://localhost:11434",
                                        "temperature": 0.27,
                                        "context_window": 1748,
                                        "lc_model": {
                                          "lc": 1,
                                          "type": "constructor",
                                          "id": [
                                            "langchain",
                                            "chat_models",
                                            "ollama",
                                            "ChatOllama"
                                          ],
                                          "kwargs": {
                                            "model": "llama3",
                                            "base_url": "http://localhost:11434",
                                            "temperature": 0.27,
                                            "context_window": 1848,
                                            "lc_model": {
                                              "lc": 1,
                                              "type": "constructor",
                                              "id": [
                                                "langchain",
                                                "chat_models",
                                                "ollama",
                                                "ChatOllama"
                                              ],
                                              "kwargs": {
                                                "model": "llama3",
                                                "base_url": "http://localhost:11434",
                                                "temperature": 0.27,
                                                "context_window": 1948,
                                                "lc_model": {
                                                  "lc": 1,
                                                  "type": "constructor",
                                                  "id": [
                                                    "langchain",
                                                    "chat_models",
                                                    "ollama",
                                                    "ChatOllama"
                                                  ],
                                                  "kwargs": {
                                                    "model": "llama2",
                                                    "base_url": "http://localhost:11434",
                                                    "temperature": 0.27,
                                                    "context_window": 3896,
                                                    "lc_model": {
                                                      "lc": 1,
                                                      "type": "constructor",
                                                      "id": [
                                                        "langchain",
                                                        "chat_models",
                                                        "ollama",
                                                        "ChatOllama"
                                                      ],
                                                      "kwargs": {
                                                        "model": "llama2",
                                                        "base_url": "http://localhost:11434",
                                                        "temperature": 0.27,
                                                        "context_window": 3996,
                                                        "lc_model": {
                                                          "lc": 1,
                                                          "type": "constructor",
                                                          "id": [
                                                            "langchain",
                                                            "chat_models",
                                                            "ollama",
                                                            "ChatOllama"
                                                          ],
                                                          "kwargs": {
                                                            "model": "llama3",
                                                            "base_url": "http://localhost:11434",
                                                            "temperature": 0.27,
                                                            "context_window": 1948,
                                                            "lc_model": {
                                                              "lc": 1,
                                                              "type": "constructor",
                                                              "id": [
                                                                "langchain",
                                                                "chat_models",
                                                                "ollama",
                                                                "ChatOllama"
                                                              ],
                                                              "kwargs": {
                                                                "model": "phi3:medium",
                                                                "base_url": "http://localhost:11434",
                                                                "temperature": 0.27,
                                                                "context_window": 1748,
                                                                "lc_model": {
                                                                  "lc": 1,
                                                                  "type": "constructor",
                                                                  "id": [
                                                                    "langchain",
                                                                    "chat_models",
                                                                    "ollama",
                                                                    "ChatOllama"
                                                                  ],
                                                                  "kwargs": {
                                                                    "model": "phi3:medium",
                                                                    "base_url": "http://localhost:11434",
                                                                    "temperature": 0.27,
                                                                    "context_window": 1848,
                                                                    "lc_model": {
                                                                      "lc": 1,
                                                                      "type": "constructor",
                                                                      "id": [
                                                                        "langchain",
                                                                        "chat_models",
                                                                        "ollama",
                                                                        "ChatOllama"
                                                                      ],
                                                                      "kwargs": {
                                                                        "model": "phi3:medium",
                                                                        "base_url": "http://localhost:11434",
                                                                        "temperature": 0.27,
                                                                        "context_window": 1948,
                                                                        "lc_model": {
                                                                          "lc": 1,
                                                                          "type": "constructor",
                                                                          "id": [
                                                                            "langchain",
                                                                            "chat_models",
                                                                            "ollama",
                                                                            "ChatOllama"
                                                                          ],
                                                                          "kwargs": {
                                                                            "model": "llama3",
                                                                            "base_url": "http://localhost:11434",
                                                                            "temperature": 0.27,
                                                                            "context_window": 1848,
                                                                            "lc_model": {
                                                                              "lc": 1,
                                                                              "type": "constructor",
                                                                              "id": [
                                                                                "langchain",
                                                                                "chat_models",
                                                                                "ollama",
                                                                                "ChatOllama"
                                                                              ],
                                                                              "kwargs": {
                                                                                "model": "llama3",
                                                                                "base_url": "http://localhost:11434",
                                                                                "temperature": 0.27,
                                                                                "context_window": 1948,
                                                                                "lc_model": {
                                                                                  "lc": 1,
                                                                                  "type": "constructor",
                                                                                  "id": [
                                                                                    "langchain",
                                                                                    "chat_models",
                                                                                    "ollama",
                                                                                    "ChatOllama"
                                                                                  ],
                                                                                  "kwargs": {
                                                                                    "model": "phi-3gguf",
                                                                                    "base_url": "http://localhost:11434",
                                                                                    "temperature": 0.27,
                                                                                    "context_window": 1848,
                                                                                    "lc_model": {
                                                                                      "lc": 1,
                                                                                      "type": "constructor",
                                                                                      "id": [
                                                                                        "langchain",
                                                                                        "chat_models",
                                                                                        "ollama",
                                                                                        "ChatOllama"
                                                                                      ],
                                                                                      "kwargs": {
                                                                                        "model": "phi-3gguf",
                                                                                        "base_url": "http://localhost:11434",
                                                                                        "temperature": 0.49,
                                                                                        "context_window": 1948,
                                                                                        "lc_model": {
                                                                                          "lc": 1,
                                                                                          "type": "constructor",
                                                                                          "id": [
                                                                                            "langchain",
                                                                                            "chat_models",
                                                                                            "ollama",
                                                                                            "ChatOllama"
                                                                                          ],
                                                                                          "kwargs": {
                                                                                            "model": "llama3",
                                                                                            "base_url": "http://localhost:11434",
                                                                                            "temperature": 0.49,
                                                                                            "context_window": 1848,
                                                                                            "lc_model": {
                                                                                              "lc": 1,
                                                                                              "type": "constructor",
                                                                                              "id": [
                                                                                                "langchain",
                                                                                                "chat_models",
                                                                                                "ollama",
                                                                                                "ChatOllama"
                                                                                              ],
                                                                                              "kwargs": {
                                                                                                "model": "llama3",
                                                                                                "base_url": "http://localhost:11434",
                                                                                                "temperature": 0.25,
                                                                                                "context_window": 1948,
                                                                                                "lc_model": {
                                                                                                  "lc": 1,
                                                                                                  "type": "constructor",
                                                                                                  "id": [
                                                                                                    "langchain",
                                                                                                    "chat_models",
                                                                                                    "ollama",
                                                                                                    "ChatOllama"
                                                                                                  ],
                                                                                                  "kwargs": {
                                                                                                    "model": "phi3",
                                                                                                    "base_url": "http://localhost:11434",
                                                                                                    "temperature": 0.25,
                                                                                                    "context_window": 1748,
                                                                                                    "lc_model": {
                                                                                                      "lc": 1,
                                                                                                      "type": "constructor",
                                                                                                      "id": [
                                                                                                        "langchain",
                                                                                                        "chat_models",
                                                                                                        "ollama",
                                                                                                        "ChatOllama"
                                                                                                      ],
                                                                                                      "kwargs": {
                                                                                                        "model": "phi3",
                                                                                                        "base_url": "http://localhost:11434",
                                                                                                        "temperature": 0.5,
                                                                                                        "context_window": 1848,
                                                                                                        "lc_model": {
                                                                                                          "lc": 1,
                                                                                                          "type": "constructor",
                                                                                                          "id": [
                                                                                                            "langchain",
                                                                                                            "chat_models",
                                                                                                            "ollama",
                                                                                                            "ChatOllama"
                                                                                                          ],
                                                                                                          "kwargs": {
                                                                                                            "model": "phi3",
                                                                                                            "base_url": "http://localhost:11434",
                                                                                                            "temperature": 0.45,
                                                                                                            "context_window": 1948,
                                                                                                            "lc_model": {
                                                                                                              "lc": 1,
                                                                                                              "type": "constructor",
                                                                                                              "id": [
                                                                                                                "langchain",
                                                                                                                "chat_models",
                                                                                                                "ollama",
                                                                                                                "ChatOllama"
                                                                                                              ],
                                                                                                              "kwargs": {
                                                                                                                "model": "phi3:3.8b-mini-instruct-4k-q4_K_M",
                                                                                                                "base_url": "http://localhost:11434",
                                                                                                                "temperature": 0.45,
                                                                                                                "context_window": 1448,
                                                                                                                "lc_model": {
                                                                                                                  "lc": 1,
                                                                                                                  "type": "constructor",
                                                                                                                  "id": [
                                                                                                                    "langchain",
                                                                                                                    "chat_models",
                                                                                                                    "ollama",
                                                                                                                    "ChatOllama"
                                                                                                                  ],
                                                                                                                  "kwargs": {
                                                                                                                    "model": "phi3:3.8b-mini-instruct-4k-q4_K_M",
                                                                                                                    "base_url": "http://localhost:11434",
                                                                                                                    "temperature": 0.45,
                                                                                                                    "context_window": 1548,
                                                                                                                    "lc_model": {
                                                                                                                      "lc": 1,
                                                                                                                      "type": "constructor",
                                                                                                                      "id": [
                                                                                                                        "langchain",
                                                                                                                        "chat_models",
                                                                                                                        "ollama",
                                                                                                                        "ChatOllama"
                                                                                                                      ],
                                                                                                                      "kwargs": {
                                                                                                                        "model": "phi3:3.8b-mini-instruct-4k-q4_K_M",
                                                                                                                        "base_url": "http://localhost:11434",
                                                                                                                        "temperature": 0.45,
                                                                                                                        "context_window": 1648,
                                                                                                                        "lc_model": {
                                                                                                                          "lc": 1,
                                                                                                                          "type": "constructor",
                                                                                                                          "id": [
                                                                                                                            "langchain",
                                                                                                                            "chat_models",
                                                                                                                            "ollama",
                                                                                                                            "ChatOllama"
                                                                                                                          ],
                                                                                                                          "kwargs": {
                                                                                                                            "model": "phi3:3.8b-mini-instruct-4k-q4_K_M",
                                                                                                                            "base_url": "http://localhost:11434",
                                                                                                                            "temperature": 0.34,
                                                                                                                            "context_window": 1748,
                                                                                                                            "lc_model": {
                                                                                                                              "lc": 1,
                                                                                                                              "type": "constructor",
                                                                                                                              "id": [
                                                                                                                                "langchain",
                                                                                                                                "chat_models",
                                                                                                                                "ollama",
                                                                                                                                "ChatOllama"
                                                                                                                              ],
                                                                                                                              "kwargs": {
                                                                                                                                "model": "phi3:3.8b-mini-instruct-4k-q4_K_M",
                                                                                                                                "base_url": "http://localhost:11434",
                                                                                                                                "temperature": 0.31,
                                                                                                                                "context_window": 1848,
                                                                                                                                "lc_model": {
                                                                                                                                  "lc": 1,
                                                                                                                                  "type": "constructor",
                                                                                                                                  "id": [
                                                                                                                                    "langchain",
                                                                                                                                    "chat_models",
                                                                                                                                    "ollama",
                                                                                                                                    "ChatOllama"
                                                                                                                                  ],
                                                                                                                                  "kwargs": {
                                                                                                                                    "model": "phi3:3.8b-mini-instruct-4k-q4_K_M",
                                                                                                                                    "base_url": "http://localhost:11434",
                                                                                                                                    "temperature": 0.26,
                                                                                                                                    "context_window": 1948,
                                                                                                                                    "lc_model": {
                                                                                                                                      "lc": 1,
                                                                                                                                      "type": "constructor",
                                                                                                                                      "id": [
                                                                                                                                        "langchain",
                                                                                                                                        "chat_models",
                                                                                                                                        "ollama",
                                                                                                                                        "ChatOllama"
                                                                                                                                      ],
                                                                                                                                      "kwargs": {
                                                                                                                                        "model": "phi3",
                                                                                                                                        "base_url": "http://localhost:11434",
                                                                                                                                        "temperature": 0.26,
                                                                                                                                        "context_window": 1148,
                                                                                                                                        "lc_model": {
                                                                                                                                          "lc": 1,
                                                                                                                                          "type": "constructor",
                                                                                                                                          "id": [
                                                                                                                                            "langchain",
                                                                                                                                            "chat_models",
                                                                                                                                            "ollama",
                                                                                                                                            "ChatOllama"
                                                                                                                                          ],
                                                                                                                                          "kwargs": {
                                                                                                                                            "model": "phi3",
                                                                                                                                            "base_url": "http://localhost:11434",
                                                                                                                                            "temperature": 0.11,
                                                                                                                                            "context_window": 1248,
                                                                                                                                            "lc_model": {
                                                                                                                                              "lc": 1,
                                                                                                                                              "type": "constructor",
                                                                                                                                              "id": [
                                                                                                                                                "langchain",
                                                                                                                                                "chat_models",
                                                                                                                                                "ollama",
                                                                                                                                                "ChatOllama"
                                                                                                                                              ],
                                                                                                                                              "kwargs": {
                                                                                                                                                "model": "phi3",
                                                                                                                                                "base_url": "http://localhost:11434",
                                                                                                                                                "temperature": 0.11,
                                                                                                                                                "context_window": 1348,
                                                                                                                                                "lc_model": {
                                                                                                                                                  "lc": 1,
                                                                                                                                                  "type": "constructor",
                                                                                                                                                  "id": [
                                                                                                                                                    "langchain",
                                                                                                                                                    "chat_models",
                                                                                                                                                    "ollama",
                                                                                                                                                    "ChatOllama"
                                                                                                                                                  ],
                                                                                                                                                  "kwargs": {
                                                                                                                                                    "model": "phi3",
                                                                                                                                                    "base_url": "http://localhost:11434",
                                                                                                                                                    "temperature": 0.59,
                                                                                                                                                    "context_window": 1448,
                                                                                                                                                    "lc_model": {
                                                                                                                                                      "lc": 1,
                                                                                                                                                      "type": "constructor",
                                                                                                                                                      "id": [
                                                                                                                                                        "langchain",
                                                                                                                                                        "chat_models",
                                                                                                                                                        "ollama",
                                                                                                                                                        "ChatOllama"
                                                                                                                                                      ],
                                                                                                                                                      "kwargs": {
                                                                                                                                                        "model": "phi3",
                                                                                                                                                        "base_url": "http://localhost:11434",
                                                                                                                                                        "temperature": 0.04,
                                                                                                                                                        "context_window": 1548,
                                                                                                                                                        "lc_model": {
                                                                                                                                                          "lc": 1,
                                                                                                                                                          "type": "constructor",
                                                                                                                                                          "id": [
                                                                                                                                                            "langchain",
                                                                                                                                                            "chat_models",
                                                                                                                                                            "ollama",
                                                                                                                                                            "ChatOllama"
                                                                                                                                                          ],
                                                                                                                                                          "kwargs": {
                                                                                                                                                            "model": "phi3",
                                                                                                                                                            "base_url": "http://localhost:11434",
                                                                                                                                                            "temperature": 1,
                                                                                                                                                            "context_window": 1648,
                                                                                                                                                            "lc_model": {
                                                                                                                                                              "lc": 1,
                                                                                                                                                              "type": "constructor",
                                                                                                                                                              "id": [
                                                                                                                                                                "langchain",
                                                                                                                                                                "chat_models",
                                                                                                                                                                "ollama",
                                                                                                                                                                "ChatOllama"
                                                                                                                                                              ],
                                                                                                                                                              "kwargs": {
                                                                                                                                                                "model": "phi3",
                                                                                                                                                                "base_url": "http://localhost:11434",
                                                                                                                                                                "temperature": 0.34,
                                                                                                                                                                "context_window": 1748,
                                                                                                                                                                "lc_model": {
                                                                                                                                                                  "lc": 1,
                                                                                                                                                                  "type": "constructor",
                                                                                                                                                                  "id": [
                                                                                                                                                                    "langchain",
                                                                                                                                                                    "chat_models",
                                                                                                                                                                    "ollama",
                                                                                                                                                                    "ChatOllama"
                                                                                                                                                                  ],
                                                                                                                                                                  "kwargs": {
                                                                                                                                                                    "model": "phi3",
                                                                                                                                                                    "base_url": "http://localhost:11434",
                                                                                                                                                                    "temperature": 0.34,
                                                                                                                                                                    "context_window": 1848,
                                                                                                                                                                    "lc_model": {
                                                                                                                                                                      "lc": 1,
                                                                                                                                                                      "type": "constructor",
                                                                                                                                                                      "id": [
                                                                                                                                                                        "langchain",
                                                                                                                                                                        "chat_models",
                                                                                                                                                                        "ollama",
                                                                                                                                                                        "ChatOllama"
                                                                                                                                                                      ],
                                                                                                                                                                      "kwargs": {
                                                                                                                                                                        "model": "phi3",
                                                                                                                                                                        "base_url": "http://localhost:11434",
                                                                                                                                                                        "temperature": 1,
                                                                                                                                                                        "context_window": 1948,
                                                                                                                                                                        "lc_model": {
                                                                                                                                                                          "lc": 1,
                                                                                                                                                                          "type": "constructor",
                                                                                                                                                                          "id": [
                                                                                                                                                                            "langchain",
                                                                                                                                                                            "chat_models",
                                                                                                                                                                            "ollama",
                                                                                                                                                                            "ChatOllama"
                                                                                                                                                                          ],
                                                                                                                                                                          "kwargs": {
                                                                                                                                                                            "model": "llama3",
                                                                                                                                                                            "base_url": "http://localhost:11434",
                                                                                                                                                                            "temperature": 1,
                                                                                                                                                                            "context_window": 1048,
                                                                                                                                                                            "lc_model": {
                                                                                                                                                                              "lc": 1,
                                                                                                                                                                              "type": "constructor",
                                                                                                                                                                              "id": [
                                                                                                                                                                                "langchain",
                                                                                                                                                                                "chat_models",
                                                                                                                                                                                "ollama",
                                                                                                                                                                                "ChatOllama"
                                                                                                                                                                              ],
                                                                                                                                                                              "kwargs": {
                                                                                                                                                                                "model": "llama3",
                                                                                                                                                                                "base_url": "http://localhost:11434",
                                                                                                                                                                                "temperature": 1,
                                                                                                                                                                                "context_window": 1148,
                                                                                                                                                                                "lc_model": {
                                                                                                                                                                                  "lc": 1,
                                                                                                                                                                                  "type": "constructor",
                                                                                                                                                                                  "id": [
                                                                                                                                                                                    "langchain",
                                                                                                                                                                                    "chat_models",
                                                                                                                                                                                    "ollama",
                                                                                                                                                                                    "ChatOllama"
                                                                                                                                                                                  ],
                                                                                                                                                                                  "kwargs": {
                                                                                                                                                                                    "model": "llama3",
                                                                                                                                                                                    "base_url": "http://localhost:11434",
                                                                                                                                                                                    "temperature": 0.46,
                                                                                                                                                                                    "context_window": 1248,
                                                                                                                                                                                    "lc_model": {
                                                                                                                                                                                      "lc": 1,
                                                                                                                                                                                      "type": "constructor",
                                                                                                                                                                                      "id": [
                                                                                                                                                                                        "langchain",
                                                                                                                                                                                        "chat_models",
                                                                                                                                                                                        "ollama",
                                                                                                                                                                                        "ChatOllama"
                                                                                                                                                                                      ],
                                                                                                                                                                                      "kwargs": {
                                                                                                                                                                                        "model": "llama3",
                                                                                                                                                                                        "base_url": "http://localhost:11434",
                                                                                                                                                                                        "temperature": 0.42,
                                                                                                                                                                                        "context_window": 1348,
                                                                                                                                                                                        "lc_model": {
                                                                                                                                                                                          "lc": 1,
                                                                                                                                                                                          "type": "constructor",
                                                                                                                                                                                          "id": [
                                                                                                                                                                                            "langchain",
                                                                                                                                                                                            "chat_models",
                                                                                                                                                                                            "ollama",
                                                                                                                                                                                            "ChatOllama"
                                                                                                                                                                                          ],
                                                                                                                                                                                          "kwargs": {
                                                                                                                                                                                            "model": "llama3",
                                                                                                                                                                                            "base_url": "http://localhost:11434",
                                                                                                                                                                                            "temperature": 0.5,
                                                                                                                                                                                            "context_window": 1448,
                                                                                                                                                                                            "lc_model": {
                                                                                                                                                                                              "lc": 1,
                                                                                                                                                                                              "type": "constructor",
                                                                                                                                                                                              "id": [
                                                                                                                                                                                                "langchain",
                                                                                                                                                                                                "chat_models",
                                                                                                                                                                                                "ollama",
                                                                                                                                                                                                "ChatOllama"
                                                                                                                                                                                              ],
                                                                                                                                                                                              "kwargs": {
                                                                                                                                                                                                "model": "llama3",
                                                                                                                                                                                                "base_url": "http://localhost:11434",
                                                                                                                                                                                                "temperature": 0.5,
                                                                                                                                                                                                "context_window": 1548,
                                                                                                                                                                                                "lc_model": {
                                                                                                                                                                                                  "lc": 1,
                                                                                                                                                                                                  "type": "constructor",
                                                                                                                                                                                                  "id": [
                                                                                                                                                                                                    "langchain",
                                                                                                                                                                                                    "chat_models",
                                                                                                                                                                                                    "ollama",
                                                                                                                                                                                                    "ChatOllama"
                                                                                                                                                                                                  ],
                                                                                                                                                                                                  "kwargs": {
                                                                                                                                                                                                    "model": "llama3",
                                                                                                                                                                                                    "base_url": "http://localhost:11434",
                                                                                                                                                                                                    "temperature": 0.27,
                                                                                                                                                                                                    "context_window": 1648,
                                                                                                                                                                                                    "lc_model": {
                                                                                                                                                                                                      "lc": 1,
                                                                                                                                                                                                      "type": "constructor",
                                                                                                                                                                                                      "id": [
                                                                                                                                                                                                        "langchain",
                                                                                                                                                                                                        "chat_models",
                                                                                                                                                                                                        "ollama",
                                                                                                                                                                                                        "ChatOllama"
                                                                                                                                                                                                      ],
                                                                                                                                                                                                      "kwargs": {
                                                                                                                                                                                                        "model": "llama3",
                                                                                                                                                                                                        "base_url": "http://localhost:11434",
                                                                                                                                                                                                        "temperature": 0.27,
                                                                                                                                                                                                        "context_window": 1748,
                                                                                                                                                                                                        "lc_model": {
                                                                                                                                                                                                          "lc": 1,
                                                                                                                                                                                                          "type": "constructor",
                                                                                                                                                                                                          "id": [
                                                                                                                                                                                                            "langchain",
                                                                                                                                                                                                            "chat_models",
                                                                                                                                                                                                            "ollama",
                                                                                                                                                                                                            "ChatOllama"
                                                                                                                                                                                                          ],
                                                                                                                                                                                                          "kwargs": {
                                                                                                                                                                                                            "model": "llama3",
                                                                                                                                                                                                            "base_url": "http://localhost:11434",
                                                                                                                                                                                                            "temperature": 0.53,
                                                                                                                                                                                                            "context_window": 1848,
                                                                                                                                                                                                            "lc_model": {
                                                                                                                                                                                                              "lc": 1,
                                                                                                                                                                                                              "type": "constructor",
                                                                                                                                                                                                              "id": [
                                                                                                                                                                                                                "langchain",
                                                                                                                                                                                                                "chat_models",
                                                                                                                                                                                                                "ollama",
                                                                                                                                                                                                                "ChatOllama"
                                                                                                                                                                                                              ],
                                                                                                                                                                                                              "kwargs": {
                                                                                                                                                                                                                "model": "llama3",
                                                                                                                                                                                                                "base_url": "http://localhost:11434",
                                                                                                                                                                                                                "temperature": 0.5,
                                                                                                                                                                                                                "context_window": 1948
                                                                                                                                                                                                              }
                                                                                                                                                                                                            }
                                                                                                                                                                                                          }
                                                                                                                                                                                                        }
                                                                                                                                                                                                      }
                                                                                                                                                                                                    }
                                                                                                                                                                                                  }
                                                                                                                                                                                                }
                                                                                                                                                                                              }
                                                                                                                                                                                            }
                                                                                                                                                                                          }
                                                                                                                                                                                        }
                                                                                                                                                                                      }
                                                                                                                                                                                    }
                                                                                                                                                                                  }
                                                                                                                                                                                }
                                                                                                                                                                              }
                                                                                                                                                                            }
                                                                                                                                                                          }
                                                                                                                                                                        }
                                                                                                                                                                      }
                                                                                                                                                                    }
                                                                                                                                                                  }
                                                                                                                                                                }
                                                                                                                                                              }
                                                                                                                                                            }
                                                                                                                                                          }
                                                                                                                                                        }
                                                                                                                                                      }
                                                                                                                                                    }
                                                                                                                                                  }
                                                                                                                                                }
                                                                                                                                              }
                                                                                                                                            }
                                                                                                                                          }
                                                                                                                                        }
                                                                                                                                      }
                                                                                                                                    }
                                                                                                                                  }
                                                                                                                                }
                                                                                                                              }
                                                                                                                            }
                                                                                                                          }
                                                                                                                        }
                                                                                                                      }
                                                                                                                    }
                                                                                                                  }
                                                                                                                }
                                                                                                              }
                                                                                                            }
                                                                                                          }
                                                                                                        }
                                                                                                      }
                                                                                                    }
                                                                                                  }
                                                                                                }
                                                                                              }
                                                                                            }
                                                                                          }
                                                                                        }
                                                                                      }
                                                                                    }
                                                                                  }
                                                                                }
                                                                              }
                                                                            }
                                                                          }
                                                                        }
                                                                      }
                                                                    }
                                                                  }
                                                                }
                                                              }
                                                            }
                                                          }
                                                        }
                                                      }
                                                    }
                                                  }
                                                }
                                              }
                                            }
                                          }
                                        }
                                      }
                                    }
                                  }
                                }
                              }
                            }
                          }
                        }
                      }
                    }
                  }
                }
              }
            }
          }
        }
      }
    }
  },
  "ollamaEmbedModel": {
    "model": "nomic-embed-text",
    "baseUrl": "http://localhost:11434",
    "similarityThreshold": 0.2,
    "k": 100
  },
  "openAIGenModel": {
    "model": "gpt-3.5-turbo",
    "openAIApiKey": "",
    "temperature": 0.5,
    "contextWindow": 948
  },
  "openAIEmbedModel": {
    "model": "text-embedding-ada-002",
    "openAIApiKey": "",
    "similarityThreshold": 0.75,
    "k": 100
  },
  "targetFolder": "Chats",
  "defaultChatName": "New Chat",
  "excludeFF": [
    "Chats",
    "*.excalidraw.md"
  ],
  "isQuickSettingsOpen": true,
  "isVerbose": true,
  "isOnboarded": true,
  "hideIncognitoWarning": false,
  "isAutostart": true
}